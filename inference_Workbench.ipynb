{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_SERIALIZED_MODEL = './my_model/my_model_1658084748.660345.pkl'\n",
    "MY_EXAMPLES = './examples.csv'\n",
    "OUTPUT_PATH = './inferences.csv'\n",
    "\n",
    "PROJECT        = ''#'gtdp-mlops-dev'\n",
    "REGION         = '' #'eu'\n",
    "TEMP_LOCATION  = './temp' # gs://gtdp_mlops_dev_mlinput/temp'\n",
    "\n",
    "\n",
    "OUTPUT_SCHEMA  = {\n",
    "                    'fields': \n",
    "                    [\n",
    "                        {'name':'job_id'        ,'type':'STRING'   , 'mode': 'REQUIRED'},\n",
    "                        {'name':'input_data'    ,'type':'STRING'   , 'mode': 'REQUIRED'},\n",
    "                        {'name':'transform_data','type':'STRING'   , 'mode': 'NULLABLE'},\n",
    "                        {'name':'output_data'   ,'type':'STRING'   , 'mode': 'NULLABLE'},\n",
    "                        {'name':'tec_dat_cre'   ,'type':'TIMESTAMP', 'mode': 'REQUIRED'},\n",
    "                    ]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job_id': 'id', 'input_data': '[[4.947543583304329, 3.384978721770141, 6.253358321057868, 2.2196608276841983], [6.606564407811608, 3.387871841096402, 2.2603987851981175, 0.7687599498001358], [7.3264910684980205, 3.041734996249156, 4.064899464009686, 0.7265987299245709], [7.165454322623381, 2.0404524073848194, 6.3113436168139305, 0.4179782219957122], [7.631371622184243, 4.159669161223599, 2.108975661920023, 1.7692167487195543], [5.163505356810251, 2.2884783524037653, 5.925285117054725, 0.9345365600233835], [7.432203226221343, 3.064280638405448, 6.248381045549924, 1.058084818450686], [7.72653456529427, 2.5576219532138422, 1.36377663018207, 2.233173987273001], [6.829406912383567, 2.0239158705319276, 4.437455754817621, 1.4016064555294137], [6.122721578790571, 2.384874079943531, 4.588292611181637, 2.252758710428669]]', 'transform_data': '[[4.947543583304329, 3.384978721770141, 6.253358321057868, 2.2196608276841983], [6.606564407811608, 3.387871841096402, 2.2603987851981175, 0.7687599498001358], [7.3264910684980205, 3.041734996249156, 4.064899464009686, 0.7265987299245709], [7.165454322623381, 2.0404524073848194, 6.3113436168139305, 0.4179782219957122], [7.631371622184243, 4.159669161223599, 2.108975661920023, 1.7692167487195543], [5.163505356810251, 2.2884783524037653, 5.925285117054725, 0.9345365600233835], [7.432203226221343, 3.064280638405448, 6.248381045549924, 1.058084818450686], [7.72653456529427, 2.5576219532138422, 1.36377663018207, 2.233173987273001], [6.829406912383567, 2.0239158705319276, 4.437455754817621, 1.4016064555294137], [6.122721578790571, 2.384874079943531, 4.588292611181637, 2.252758710428669]]', 'output_data': '\"[\\'virginica\\' \\'setosa\\' \\'versicolor\\' \\'versicolor\\' \\'setosa\\' \\'virginica\\'\\\\n \\'virginica\\' \\'setosa\\' \\'versicolor\\' \\'virginica\\']\"', 'tec_dat_cre': 1658152499.074559}\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# testing without apache_beam\n",
    "from adeo_mlops_lib import mlopslib\n",
    "\n",
    "\n",
    "f = open(MY_EXAMPLES, \"r\")\n",
    "mylist = f.read().splitlines()\n",
    "mylist = [v.split(',') for v in mylist ]\n",
    "\n",
    "input = [list(map(float, suba)) for suba in mylist]\n",
    "\n",
    "mlopslib_x = mlopslib.load(MY_SERIALIZED_MODEL)\n",
    "\n",
    "transform = input\n",
    "predictions = mlopslib_x.predict(transform)\n",
    "\n",
    "output = mlopslib_x.output('id',input,transform,predictions)\n",
    "\n",
    "print(output)\n",
    "\n",
    "del mlopslib_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f4ccd64dca0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n",
    "\n",
    "from apache_beam.dataframe.io import read_csv\n",
    "from apache_beam.dataframe.convert import to_dataframe\n",
    "from apache_beam.dataframe.convert import to_pcollection\n",
    "\n",
    "import apache_beam.runners.interactive.interactive_beam as ib\n",
    "\n",
    "from adeo_mlops_lib import mlopslib\n",
    "\n",
    "mlopslib_x = mlopslib.load(MY_SERIALIZED_MODEL)\n",
    "\n",
    "class Predict(beam.DoFn):\n",
    "  def process(self, input):\n",
    "    transform = mlopslib_x.transform(input) \n",
    "    inference = mlopslib_x.predict(transform)\n",
    "    yield mlopslib_x.output('id', input, transform, inference) # converts the output to the desired format\n",
    "\n",
    "\n",
    "beam_options = {}\n",
    "#p = beam.Pipeline(InteractiveRunner())\n",
    "\n",
    "p = beam.Pipeline(options=PipelineOptions(beam_options, project=PROJECT, region=REGION, temp_location=TEMP_LOCATION))\n",
    "\n",
    "batch_rows = (\n",
    "    p \n",
    "    | 'ReadLocal'  >> beam.io.ReadFromText(MY_EXAMPLES)\n",
    "    | 'Split'      >> beam.Map(lambda record: record.split(','))\n",
    "    | 'Predict'    >> beam.ParDo(Predict())\n",
    "    | 'WriteLocal' >> beam.io.WriteToText(OUTPUT_PATH)\n",
    ")\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Showcase",
   "language": "python",
   "name": "showcase"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
